{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2\n",
    "\n",
    "Objetivo: Modelagem de Tópicos\n",
    "\n",
    "a) Estimar os parâmetros do modelo LDA no corpus e salvar na variável ldamodel. Extrair 10 tópicos usando corpus e id_map, com os parâmetros 'passes' = 25 e 'random_state' = 35.\n",
    "\n",
    "b) Usando ldamodel, encontre uma lista dos 10 tópicos e das 10 palavras mais significativas em cada tópico. Isso deve ser estruturado como uma lista de 10 tuplas.\n",
    "\n",
    "c) Baseando-se na seguinte lista de tópicos, relacione com os tópicos encontrados pelo algoritmo gensim no corpus. A lista de tópicos pode ser estendida por vocês.\n",
    "\n",
    "    Tópicos:\n",
    "    Saúde, Ciência, Automóveis, Política, Governo, Viagem,\n",
    "    Computadores e TI, Esportes, Negócios, Sociedade e\n",
    "    Estilo de vida, Religião, Educação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newsgroups.csv', 'rb') as f:\n",
    "    newsgroup_data = pickle.load(f)\n",
    "\n",
    "vect = CountVectorizer(min_df=20, max_df=0.2, stop_words='english', \n",
    "                       token_pattern='(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b')\n",
    "X = vect.fit_transform(newsgroup_data)\n",
    "\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamulticore.LdaModel\n",
    "ldamodel = lda(corpus=corpus, num_topics=10, id2word = id_map, passes=25,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.056*\"edu\" + 0.043*\"com\" + 0.033*\"thanks\" + 0.022*\"mail\" + 0.021*\"know\" + 0.020*\"does\" + 0.014*\"info\" + 0.012*\"monitor\" + 0.010*\"looking\" + 0.010*\"don\"'),\n",
       " (1,\n",
       "  '0.024*\"ground\" + 0.018*\"current\" + 0.018*\"just\" + 0.013*\"want\" + 0.013*\"use\" + 0.011*\"using\" + 0.011*\"used\" + 0.010*\"power\" + 0.010*\"speed\" + 0.010*\"output\"'),\n",
       " (2,\n",
       "  '0.061*\"drive\" + 0.042*\"disk\" + 0.033*\"scsi\" + 0.030*\"drives\" + 0.028*\"hard\" + 0.028*\"controller\" + 0.027*\"card\" + 0.020*\"rom\" + 0.018*\"floppy\" + 0.017*\"bus\"'),\n",
       " (3,\n",
       "  '0.023*\"time\" + 0.015*\"atheism\" + 0.014*\"list\" + 0.013*\"left\" + 0.012*\"alt\" + 0.012*\"faq\" + 0.012*\"probably\" + 0.011*\"know\" + 0.011*\"send\" + 0.010*\"months\"'),\n",
       " (4,\n",
       "  '0.025*\"car\" + 0.016*\"just\" + 0.014*\"don\" + 0.014*\"bike\" + 0.012*\"good\" + 0.011*\"new\" + 0.011*\"think\" + 0.010*\"year\" + 0.010*\"cars\" + 0.010*\"time\"'),\n",
       " (5,\n",
       "  '0.030*\"game\" + 0.027*\"team\" + 0.023*\"year\" + 0.017*\"games\" + 0.016*\"play\" + 0.012*\"season\" + 0.012*\"players\" + 0.012*\"win\" + 0.011*\"hockey\" + 0.011*\"good\"'),\n",
       " (6,\n",
       "  '0.017*\"information\" + 0.014*\"help\" + 0.014*\"medical\" + 0.012*\"new\" + 0.012*\"use\" + 0.012*\"000\" + 0.012*\"research\" + 0.011*\"university\" + 0.010*\"number\" + 0.010*\"program\"'),\n",
       " (7,\n",
       "  '0.022*\"don\" + 0.021*\"people\" + 0.018*\"think\" + 0.017*\"just\" + 0.012*\"say\" + 0.011*\"know\" + 0.011*\"does\" + 0.011*\"good\" + 0.010*\"god\" + 0.009*\"way\"'),\n",
       " (8,\n",
       "  '0.034*\"use\" + 0.023*\"apple\" + 0.020*\"power\" + 0.016*\"time\" + 0.015*\"data\" + 0.015*\"software\" + 0.012*\"pin\" + 0.012*\"memory\" + 0.012*\"simms\" + 0.011*\"port\"'),\n",
       " (9,\n",
       "  '0.068*\"space\" + 0.036*\"nasa\" + 0.021*\"science\" + 0.020*\"edu\" + 0.019*\"data\" + 0.017*\"shuttle\" + 0.015*\"launch\" + 0.015*\"available\" + 0.014*\"center\" + 0.014*\"sci\"')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=10, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O assunto principal do tópico 0 é: Educação\n",
      "O assunto principal do tópico 1 é: Automóveis\n",
      "O assunto principal do tópico 2 é: Computadores e TI\n",
      "O assunto principal do tópico 3 é: Religião\n",
      "O assunto principal do tópico 4 é: Automóveis\n",
      "O assunto principal do tópico 5 é: Esportes\n",
      "O assunto principal do tópico 6 é: Saúde\n",
      "O assunto principal do tópico 7 é: Religião\n",
      "O assunto principal do tópico 8 é: Computadores e TI\n",
      "O assunto principal do tópico 9 é: Ciência\n"
     ]
    }
   ],
   "source": [
    "lista = ['Educação', 'Automóveis', 'Computadores e TI', 'Religião',  'Automóveis', 'Esportes', 'Saúde', 'Religião', \n",
    "         'Computadores e TI', 'Ciência']\n",
    "for i in range(0,10):\n",
    "    print('O assunto principal do tópico {} é: {}'.format(i, lista[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
